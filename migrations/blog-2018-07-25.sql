# ************************************************************
# Sequel Pro SQL dump
# Version 4541
#
# http://www.sequelpro.com/
# https://github.com/sequelpro/sequelpro
#
# Host: 127.0.0.1 (MySQL 5.5.5-10.3.8-MariaDB)
# Database: blog
# Generation Time: 2018-07-25 10:29:10 +0000
# ************************************************************


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;


# Dump of table Articles
# ------------------------------------------------------------

DROP TABLE IF EXISTS `Articles`;

CREATE TABLE `Articles` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `link` varchar(45) COLLATE utf8mb4_unicode_ci NOT NULL,
  `title` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT 'title',
  `date` date DEFAULT NULL,
  `category` varchar(52) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT 'category',
  `content` mediumtext COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `thumbnail` varchar(45) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT 'dual-parallax.jpg',
  `tags` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT 'tag1,tag2',
  `wip` varchar(3) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT 'yes',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

LOCK TABLES `Articles` WRITE;
/*!40000 ALTER TABLE `Articles` DISABLE KEYS */;

INSERT INTO `Articles` (`id`, `link`, `title`, `date`, `category`, `content`, `thumbnail`, `tags`, `wip`)
VALUES
	(1,'lamp_stack_on_centos','Setting up a LAMP Stack on CentOS 7','2018-02-22','development','<p>Welcome to the first post of my blog! This article will teach you how to set up a LAMP <code>Linux(CentOS), Apache, MySQL, Python</code> web server from scratch, just like how I did to get this blog running. This guide will go through everything and not all of it may apply to your circumstance, so feel free to skip ahead using the table of contents.</p>\r\n<h4>Table of Contents</h4>\r\n<ul>\r\n    <li><a href=\"#0x100\">The DNS and Web Server</a></li>\r\n    <li><a href=\"#0x200\">Initial Server Setup</a></li>\r\n    <li><a href=\"#0x300\">AMP\'ed up</a></li>\r\n    <li><a href=\"#0x400\">The Apache Config</a></li>\r\n</ul>\r\n\r\n<h3 id=\"0x100\">0x100: the DNS and web server</h3><hr>\r\n<p>The DNS (Domain Name System) is a system that resolves a server\'s domain name eg. <code>blog.justinduch.com</code> into an IP address. In order for your webpage to be viewable, you must point your domain name to the webserver.</p>\r\n<p>As this process is different for every domain name registrar and server provider it is up to you to find the documentation to do this for your specific setup. Once you have a sever and domain name aswell as pointed them, we can continue with the guide.</p>\r\n\r\n<h3 id=\"0x200\">0x200: initial server setup</h3><hr>\r\n<p>Once you have your new server, you can log into it through SSH with it\'s public IP address. On Linux/Mac machines, use the command:</p>\r\n<pre>[user@okcomputer]$ ssh root@SERVER_IP</pre>\r\n<p>or connect through PUTTY on a Windows machine.</p>\r\n\r\n<h4>0x201: adding a new user</h4>\r\n<p>Now you are logged in as the <code>root</code> user, which is the administrative user in a Linux environment and is given heightend privilages. Because of this, we will create a new user that we will use to log in from now in order to help prevent making any destructive changes on accident.</p>\r\n<pre>[root@okserver]# useradd USER_NAME</pre>\r\n<p>Now you can assign the user a password:</p>\r\n<pre>[root@okserver]# passwd USER_NAME</pre>\r\n<p>Our new user has been set up, but it only has regular user privilages. If we ever want to do administrative tasks on the server (like installing packages in the later sections), our regular user will be denied access. To avoid having to go back to root, we can set up our user as a \'super user\'. This allows the user to run commands with root privilages by adding <code>sudo</code> before each command.</p>\r\n<p>To do this we will add our user to the <code>wheel</code> group. By default, on CentOS, members of the <code>wheel</code> group have sudo privileges.</p>\r\n<pre>[root@okserver]# usermod -aG wheel USER_NAME</pre>\r\n\r\n<h4>0x202: configuring ssh</h4>\r\n<p>To make our server more secure we will configure the SSH daemon to disallow remote SSH access from root and change the deafult SSH port. Changing the default port from 22 to someting more unique will help to stop many automated attacks, and make it harder to guess which port SSH is accessible from. You can enter any port number from 1024 to 32,767.</p>\r\n<p>Open the configuration file on your text editor eg. vi or nano:</p>\r\n<pre>[root@okserver]# vi /etc/ssh/sshd_config</pre>\r\n<p>Look for the lines:</p>\r\n<pre>...&#13;&#10;Port 22&#13;&#10;...&#13;&#10;#PermitRootLogin yes</pre>\r\n<p>and change them to:</p>\r\n<pre>...&#13;&#10;Port YOUR_PORT_NUMBER&#13;&#10;...&#13;&#10;PermitRootLogin no</pre>\r\n<p>Now that we have made our changes, we will restart SSH and test our configuration:</p>\r\n<pre>[root@okserver]# systemctl reload ssh</pre>\r\n<p>Open a <b>new</b> terminal window (do not disconnect from the old session until we can verify that the config works) and connect with the command:</p>\r\n<pre>[user@okcomputer]$ ssh -p PORT user@SERVER_IP</pre>\r\n<p>You should now be logged in as your new user through the new SSH port. If your server has a firewall you may also want to allow TCP connections through the new port and block the old port.</p>\r\n\r\n<h3 id=\"0x300\">0x300: AMP\'ed up</h3><hr>\r\n<p>With our server configured we can now go through the the final 3 letters of the LAMP stack.</p>\r\n<p>Before we install anything we should update the system:</p>\r\n<pre>[user@okserver]$ sudo yum -y update</pre>\r\n<p>Remember that we need to use <code>sudo</code> from now on to gain root privilages!</p>\r\n<p>From now on this guide will use vim instead of vi as it\'s text editor, to install vim enter:</p>\r\n<pre>[user@okserver]$ sudo yum install vim</pre>\r\n\r\n<h4>0x301: a for apache</h4>\r\n<p>Install Apache with:</p>\r\n<pre>[user@okserver]$ sudo yum install httpd</pre>\r\n<p>now you can start and enable the service:</p>\r\n<pre>[user@okserver]$ sudo systemctl start httpd.service&#13;&#10;[user@okserver]$ sudo systemctl enable httpd.service</pre>\r\n\r\n<h4>0x302: m for mysql</h4>\r\n<p>We are actually installing MariaDB for our database, but it still starts with a \'m\' so it counts.</p>\r\n<pre>[user@okserver]$ sudo yum install mariadb mariadb-server</pre>\r\n<p>start and enable it:</p>\r\n<pre>[user@okserver]$ sudo systemctl start mariadb&#13;&#10;[user@okserver]$ sudo systemctl enable mariadb</pre>\r\n<p>Now you will want to set up the database. Add a root user with:</p>\r\n<pre>[user@okserver]$ mysqladmin -u root password PASSWORD</pre>\r\n<p>You can test it by connecting to the database with:</p>\r\n<pre>[user@okserver]$ mysql -u root -p</pre>\r\n\r\n<h4>0x303: p for python</h4>\r\n<p>CentOS actually comes with Python2.7 by deafult, so if you are one of those neanderthals who still use 2.7 you can skip this step. For the rest of us intellectuals, you will need to install install IUS, which stands for Inline with Upstream Stable. IUS provides the Red Hat Package Manager (RPM) packages for some newer versions of select software.</p>\r\n<pre>[user@okserver]$ sudo yum install https://centos7.iuscommunity.org/ius-release.rpm</pre>\r\n<p>Now you can install Python3:</p>\r\n<pre>[user@okserver]$ sudo yum install python36u</pre>\r\n<p>You may also want to install pip and the development package needed for the mysqldb module:</p>\r\n<pre>[user@okserver]$ sudo yum install python36u-pip python36u-devel</pre>\r\n\r\n<p>Now your LAMP stack is installed! The next section goes through the Apache config to get you to the testing page.</p>\r\n\r\n<h3 id=\"0x400\">0x400: the apache config</h3><hr>\r\n<p>This section will go through how to get a set up a virtual host in Apache. You can choose many different ways to set up a virtual host, this guide will show the way I did it.</p>\r\n<p>Create the required directories for the website:</p>\r\n<pre>[user@okserver]$ sudo mkdir /var/www/YOUR_DOMAIN&#13;&#10;[user@okserver]$ sudo mkdir /var/www/YOUR_DOMAIN</span>/cgi-bin&#13;&#10;[user@okserver]$ sudo mkdir /var/www/YOUR_DOMAIN/html&#13;&#10;[user@okserver]$ sudo mkdir /var/www/YOUR_DOMAIN/conf</pre>\r\n<p><code>cgi-bin</code> is the directory where you will keep your scripts.</p>\r\n<p><code>html</code> is the document root for Apache.</p>\r\n<p><code>conf</code> is the directory where your virtual host config is placed.</p>\r\n<p>Now create <code>vhost.conf</code> in the <code>conf</code> directory:</p>\r\n<pre>[user@okserver]$ sudo touch /var/www/YOUR_DOMAIN/conf/vhost.conf</pre>\r\n<p>and and edit it: <pre>[user@okserver]$ sudo vim /var/www/example.com/conf/vhost.conf</pre> Here is a very basic example where <code>example.com</code> is my domain name:</p>\r\n<pre>\r\n&ltVirtualHost *:80&gt\r\n    ServerAdmin admin@example.com\r\n    ServerName example.com\r\n    ServerAlias /app/ \"/var/www/example.com/cgi-bin/\"\r\n    DocumentRoot /var/www/example.com/html\r\n&lt/VirtualHost&gt\r\n</pre>\r\n<p>Now we can edit the Apache config to include this virtual host config:</p>\r\n<pre>[user@okserver]$ sudo vim /etc/httpd/conf/httpd.conf</pre>\r\n<p>and add this line to the end of the file:</p>\r\n<pre>Include /var/www/example.com/conf/vhost.conf</pre>\r\n<p>Restart Apache with:</p>\r\n<pre>[user@okserver]$ sudo apachectl graceful</pre>\r\n<p>That\'s it! You can test if your web server works by typing your domain into the browser, which should direct you to Apache\'s testing page. For more config options see the <a href=\"https://httpd.apache.org/docs/2.4/vhosts/\" target=\"_blank\">official documentation</a>.</p>','lamp-stack-thumb.png','linux,centos,apache,mysql,python','no'),
	(2,'ssl_and_encryption','SSL and Encryption','2018-04-02','development','<p>TLS (Transfer Layer Security) / SSL (Secure Socket Layer) are standard, cryptographic protocols that establish security over computer networks, between a web server and a browser. SSL provides a trusted environment where all data being transmitted is encrypted.</p>\r\n                <p>This article is technically a continuation of my <a href=\"/article/lamp_stack_on_centos\" target=\"_blank\">last article</a> where we set up a CentOs7 server with Apache, and will go through explaining SSL aswell as setting it up our sever.</p>\r\n                <h4>table of contents</h4>\r\n                <ul>\r\n                    <li><a href=\"#0x100\">TLS/SSL?</a></li>\r\n                    <li><a href=\"#0x200\">A Primer on Encryption and SSL</a></li>\r\n                    <li><a href=\"#0x300\">The SSL Certificate</a></li>\r\n                    <li><a href=\"#0x400\">Let\'s Encrypt</a></li>\r\n                </ul>\r\n\r\n                <h3 id=\"0x100\">0x100: TLS/SSL?</h3><hr>\r\n                <p>The terms SSL and TLS are often used interchangeably or in conjunction with each other (TLS/SSL), but one is in fact the predecessor of the other — SSL 3.0 served as the basis for TLS 1.0 which, as a result, is sometimes referred to as SSL 3.1.</p>\r\n                <p>As SSL was named by Netscape, the creators of the protocol, it was changed to TLS to avoid any legal issues with them so that the protocol could be \"open and free\". It also hints at the idea that the protocol works over any bidirectional stream of bytes, not just Internet-based sockets.</p>\r\n                <p>In order to prevent any confusion we will refer to TLS/SSL as just SSL from now on.</p>\r\n\r\n                <h3 id=\"0x200\">0x200: a primer on encryption and SSL</h3><hr>\r\n                <h4>0x201: asymertric and symmetric encryption</h4>\r\n                <p>Asymmetric encryption (or public-key cryptography) uses a separate key for encryption and decryption. Anyone can use the encryption key (public key) to encrypt a message. However, decryption keys (private keys) are secret. This way only the intended receiver can decrypt the message.</p>\r\n                <p>Asymmetric keys are typically 1024 or 2048 bits. However, keys smaller than 2048 bits are no longer considered safe to use. Though larger keys can be created, the increased computational burden is so significant that keys larger than 2048 bits are rarely used. To put it into perspective, it would take an average computer more than 14 billion years to crack a 2048-bit certificate.</p>\r\n                <p>Symmetric encryption (or pre-shared key encryption) uses a single key to both encrypt and decrypt data. Both the sender and the receiver need the same key to communicate.</p>\r\n                <p>Symmetric key sizes are typically 128 or 256 bits, where a larger key is harder to crack. For example, a 128-bit key has <code>340,282,366,920,938,463,463,374,607,431,768,211,456</code> encryption code possibilities.</p>\r\n                <p>Whether a 128-bit or 256-bit key is used depends on the encryption capabilities of both the server and the client software. SSL Certificates do not dictate what key size is used. </p>\r\n\r\n                <h4>0x202: SSL</h4>\r\n                <p>An SSL encrypted connection is generated through both asymmetric and symmetric cryptography through an SSL handshake. In SSL communications, the server’s SSL Certificate contains an asymmetric public and private key pair. The session key that the server and the browser create during the SSL Handshake is symmetric. In essence:</p>\r\n                <ul>\r\n                    <li>The handshake begins when a client connects to an SSL-enabled server requesting a secure connection.</li>\r\n                    <li>The server then provides identification in the form of a digital certificate. The certificate contains the server name, the trusted certificate authority (CA) that vouches for the authenticity of the certificate, and the server\'s public encryption key.</li>\r\n                    <li>The client confirms the validity of the certificate before proceeding and then creates a symmetric session key and encrypts it with the server\'s asymmetric public key. Then sends it to the server.</li>\r\n                </ul>\r\n                <p>This concludes the handshake and begins the secured connection, which is encrypted and decrypted with the session key until the connection closes. If any one of the above steps fails, then the SSL handshake fails and the connection is not created.</p>\r\n\r\n                <h3 id=\"0x300\">0x300: the SSL certificate</h3><hr>\r\n                <p>The SSL certificate is the most important component when generating an SSL connection between the client and server. Anyone can create a certificate, but browsers only trust certificates that come from an organization on their list of trusted CAs. Browsers come with a pre-installed list of trusted CAs, known as the Trusted Root CA store. In order to be added to the Trusted Root CA store and thus become a Certificate Authority, a company must comply with and be audited against security and authentication standards established by the browsers.</p>\r\n                <p>SSL Certificates will contain details of whom the certificate has been issued to. This includes the domain name or common name, serial number; the details of the issuer; the period of validity - issue date and expiry date; SHA Fingerprints; subject public key algorithm, subject\'s public key; certificate signature algorithm, certificate signature value. Other important details such as the type of certificate, SSL/TLS version, Perfect Forward Secrecy status, and cipher suite details are included. Organization validated and extended validation certificates also contain verified identity information about the owner of the website, including organization name, address, city, state and country.</p>\r\n                <p>For our server we will get an SSL certificate from Let\'s Encrypt, a free, automated, and open CA, run for the public’s benefit.</p>\r\n\r\n                <h3 id=\"0x400\">0x0400: let\'s encrypt</h3><hr>\r\n                <p>The first step to using Let\'s Encrypt to obtain an SSL certificate is to install the <code>certbot</code> software on our server. But before we begin, we must will need to enable the EPEL repository, which provides additional packages for CentOS, including the <code>certbot</code> package we need. We will also need to install the <code>mod_ssl</code> module to correctly serve encrypted traffic.</p>\r\n                <pre>[user@okserver]$ sudo yum install epel-release&#13;&#10;[user@okserver]$ sudo yum install mod_ssl python-certbot-apache</pre>\r\n\r\n                <h4>0x202: requesting a certificate</h4>\r\n                <p>Using <code>certbot</code> to generate a certificate is quite easy. The client will automatically obtain and install a new SSL certificate that is valid for the domains provided as parameters. To execute the interactive installation and obtain the certificates, run the certbot command with:</p>\r\n                <pre>[user@okserver]$ sudo certbot --apache -d YOUR_DOMAIN -d OPTIONAL_DOMAIN</pre>\r\n                <p>We will be presented with a step-by-step guide to customize our certificate options. We will be asked to provide an email address for lost key recovery and notices. If our Virtual Host files do not specify the domain they serve explicitly using the <code>ServerName</code> directive, we will be asked to choose the Virtual Host file (the default ssl.conf file should work).</p>\r\n                <p>That\'s pretty much it. The generated certificate files should be available within a subdirectory named after your base domain in the <code>/etc/letsencrypt/live</code> directory. However, as the default SSL configuration shipped with CentOS\'s version of Apache is a bit dated and as such, it is vulnerable to some more recent security issues and is recommended that we select more secure SSL options. I suggest going through Remy van Elst\'s <a href=\"https://raymii.org/s/tutorials/Strong_SSL_Security_On_Apache2.html\" target=\"blank\">tutorial</a> on strong SSL security on the Apache2 webserver, as it does a better job of explaining it\'s solutions than I would.</p>','ssl-enc-thumb.png','ssl,tls,encryption,centos,apache','no'),
	(3,'how_do_you_write_a_blog','How the Fuck Do You Write a Blog?','2018-05-30','development','<p>So far this blog has averaged 0.6 articles per month (including this one) since it was launched in Feburary. Normally you would assume this is just because I\'m lazy or that my social anxiety prevents me from writing anything on the internet because of a constant fear of judgement. And normally you\'d be right, and you are. But it\'s also because of something else.</p>\r\n<p>When I was first creating this blog, I wanted to make everything from scratch (the idiom, not the language) and I really do mean EVERYTHING. Flask? Literally any web framework? Why would I need that when I have Jinja and CGI? URL endpoints? HAH! I could just use the Apache config to map everything! Bootstrap?? WHAT A JOKE! I DON\'T NEED THAT! I\'M A CSS MASTER!</p>\r\n<p>Obviously this was a terrible idea that came from my original plans to have the entire website emulate the command line (which is also a terrible idea that I also have no idea how to do). So now four months later, we will look at the old site and laugh at how stupid I was.</p>\r\n<p>Right before I wrote this article, I mapped the old site on the Wayback Machine so you could go and <a target=\"_blank\" href=\"https://web.archive.org/web/20180529040508/https://blog.justinduch.com\">look at all 8 pages here.</a> You can also see the source code up to the final commit before this redesign <a target=\"_blank\" href=\"https://github.com/apt-helion/blog/tree/484e9c3d808e08ab41605a3c8a36c4793ba49274\">here.</a> I\'ve included some pictures in case you were to lazy to click on those.</p>\r\n<h4>table of contents</h4>\r\n<ul>\r\n    <li><a href=\"#0x100\">The Looks</a></li>\r\n    <li><a href=\"#0x200\">The Logic</a></li>\r\n    <li><a href=\"#0x300\">The Redesign</a></li>\r\n    <li><a href=\"#0x400\">What\'s Next</a></li>\r\n</ul>\r\n\r\n<h3 id=\"0x100\">0x100: The Looks</h3><hr>\r\n<p>There isn\'t too much to say here apart from: \'it isn\'t very nice\'. It was my first time using CSS grid in any real capacity, and while I do like it - probably more than Bootstrap, I wasn\'t able to do very much with my more limited CSS knowledge. You can see I had my original plans in mind while desiging it, with all it\'s plain-ness, but not a good minimalist plain, the bad, uninteresting plain.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/blog1.0-root.png\" alt=\"image-alternative\"><sub>Figure 0: The homescreen with the tree style web page directory</sub>\r\n<p>Let\'s just start with the homepage <code>/</code>. It\'s actually okay in my opinion, probably the best page in the site. The tree style directory map looks decent in the center, making the command line design inspiration very clear. Overall I don\'t hate it, although it is useless because no one would need to go to it.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/blog1.0-articles.png\" alt=\"image-alternative\"><sub>Figure 1: The articles page</sub>\r\n<p>Clicking on articles takes us to <code>/articles</code> and now we face the horror. This is pretty much what the entire site looks like. A harsh contrast of black and white making it very tough on the eyes. The command line design continues with the header showing a nice \'pwd\' which displays your current directory. The tree style pages do not suit the format of a sidebar, and makes it look out of place. If you click on an article, you can see that the sidebar will grow along with the length of the article, but the tree will stay at the top, making the left side wasted space. The design is pretty utilitarian (in the bad way) and makes no attempt to please the reader.</p>\r\n<p>That\'s all I have to say about the asthetics, I don\'t know how to properly critque this. I\'m not a designer by any means and this should have shown you why.</p>\r\n\r\n<h3 id=\"0x200\">0x200: The Logic</h3><hr>\r\n<p>Here is the real monster, the reason I haven\'t bothered to write any posts, and maybe even my worst attempt at designing a piece of software I\'ve ever written. I\'m not sure on where to even start, so many things are just wrong and inefficent.</p>\r\n<p>How about the things I didn\'t do? Continuing on from the intro, I didn\'t use any web frameworks with only Jinja as a templating engine and pure CGI magic with Apache rewrite rules to change the URL.</p>\r\n<p>What does this mean? It means that in order to get the blog\'s content to do what I wanted (which was to have each article be accessible from it\'s own URL instead of using a GET request with an ID for the database) the articles had to be in the <code>html</code> folder for Apache to serve them to the user. And since these articles were in the <code>html</code> folder and not <code>cgi-bin</code>, Jinja could not render them, which meant I had no templating for my articles. Of course this then meant that everytime I would have to make a change to the general layout of the blog, I would have do it to the layout for Jinja templating as well as every article in the <code>html</code> folder. Oh no.</p>\r\n<p>My <code>cgi-bin</code> scripts also suffered from this as I had to rewrite the URL for each page. Here\'s a small peak of my Apache config (since it isn\'t on GitHub).</p>\r\n<pre>\r\nRewriteEngine On\r\nRewriteRule ^/$ /index.html [PT]\r\n# Fix later\r\nRewriteRule ^/articles/$ /app/articles [PT]\r\nRewriteRule ^/articles/security$ /app/security [PT]\r\nRewriteRule ^/articles/misc$ /app/misc [PT]\r\nRewriteRule ^/info$ /app/info [PT]\r\nRewriteRule ^/contact-me$ /app/contact [PT]\r\n</pre>\r\n<p>Yeah, it isn\'t pretty. Note the fix later comment.</p>\r\n<p>This caused me a lot of work to be done on even the tinyest change, and really put me off on working on it. That is until I decided to burn it and start again.</p>\r\n\r\n<h3 id=\"0x300\">0x300: The Redesign</h3><hr>\r\n<p>What you are reading now is blog 2.0, the redesign. I\'ve made many improvements to make the website better to view and develop. The biggest change as you can imagine is the use of an actual web framework. The blog uses <a href=\"https://github.com/yevrah/simplerr\" target=\"_blank\">simplerr</a>, a framework one of my co-workers made, and one that I find easier to use than Flask (although that may be because I\'ve used it more). It\'s also using a Bootstrap template, so no more plain ugly.</p>\r\n<p>All of this and more such as the tagging system have been made 1 day faster (2 days) than what blog 1.0 took (3 days), which really shows how much easier using other people\'s stuff is. Obviously, there\'s much more to improve, but that is mainly on my side to make it easier to manage/write articles.</p>\r\n\r\n<h3 id=\"0x400\">0x400: What\'s Next</h3><hr>\r\n<p>A big feature that\'s standard of every blogging site is the ability to write articles on the site and then uploading it to the database. Right now I write it in HTML using Vim and then manually edit the database. This is pretty inefficent and it wouldn\'t be too hard to add a text editor to the site, but right now I do not want to deal with authentication (so that only I can see and upload in progess articles), so this feature is on hold. I simply do not post enough for this to be a major problem right now ;)</p>\r\n<p class=\"extra-info\"><b>Update 2018-05-31:</b> jks nvm that was easy. I didn\'t need auth, just set an environment variable for the production server, so you can only edit articles on dev machines.</p>','blog1.0-404.png','blogpost','no'),
	(4,'spds_release','Spotify Playlist Depression Score','2018-06-15','development','<sub>Calculating an emotion is not always the best or easiest thing to do.</sub>\r\n<p><a href=\"https://playlistdepressionscore.com\">Spotify Playlist Depression Score</a> is a web application I built to determine how depressing a playlist is from it\'s songs. This article explains how I built it and how it works. As of writing, SPDS is on it\'s 1.0 release, so keep in mind  that there are a lot of improvement to be made, and that this article may not always be up to date. To view the most up to date changes, go through the <a href=\"https://github.com/apt-helion/spds/releases\">changelog on GitHub</a>  or view all SPDS articles through the <a href=\"/tag/spds\">#SPDS tag.</a></p>\r\n<h4>Table of Contents</h4>\r\n<ul>\r\n    <li><a href=\"#0x100\">The Architecture</a></li>\r\n    <li><a href=\"#0x200\">The Logic</a></li>\r\n</ul>\r\n\r\n<h3 id=\"0x100\">0x100: The Architecture</h3><hr>\r\n<p>A big change from the development of this blog is the use of Flask as the web framework. This decision was almost entirely made by the fact that I had no idea how to use sessions in Simplerr at that time (although as it turns out they are functionally the same).  This wasn\'t detrimental in any way, but if I was bothered to redo the application I wouldn\'t be using Flask.</p>\r\n<p>The application heavily relies on AngularJS, which was a real walk into the unknown for me. I\'ve never done much high level front end development, but making a smooth user experience was a must for this project. Angular just does an AJAX call on a Flask endpoint and displays it when it is received. This seems like a small thing, but it allows me to have a proper loading screen and display much more information to the user. Overall I\'d say it looks pretty nice, although I can\'t say the same for the code.</p>\r\n\r\n<h3 id=\"0x100\">0x200: The Logic</h3><hr>\r\n<p>If you are looking here to find some incredibly advanced mathematics and natural language processing to see how to determine depression, I\'m sorry but you\'re going to be very disappointed. While I do one day hope to be able to make it more advanced (and useful), this project was more of a learning exercise for a few technologies, and as such, the code behind it is quite simple.</p>\r\n<p>The reason it\'s the \'<strong>Spotify</strong> Playlist Depression Score\' instead of just \'Playlist Depression Score\' is because the Spotify API is an easy way to make sure I can find every song in the playlist. Spotify also does an audio analysis on every track they have. Included with this is a field called \'valence\', which measures from 1 to 0 how happy the audio for the track is, where 1 is MAXIMUM HAPPY and 0 is depression. This means that half our job is already done for us! YAY! Now all that\'s left is the lyrics.</p>\r\n<p>Unfortunately Spotify left us the hardest part of calculating depression. While audio sadness can be somewhat easily determined by looking a what chords are being played, the lyrics are much more difficult as we would need to know what the entire song \'means\'. The application would need to be able to understand what the words mean and what they mean when they are sung together. This is much too hard for me so I took the easy way out.</p> \r\n<p>First we use the Genius API to get our lyrics. However, for some reason getting a track from the API won\'t give us the lyrics, so instead we use the API to find the URL to the Genius website where we can scrape the lyrics from (luckily they are all under a CSS class called \'lyrics\' which makes it very easy to find with BeautifulSoup). Now we go through the song word by word picking out sad words and adding them to a score. I just took this <a href=\"https://github.com/motazsaad/emotion-lexicon\">lexicon</a> and used the emotions most commonly associated with depression. In order to get the valence to match the 1 to 0 scale of Spotify\'s audio, we find the percentage of sad words to lyrics and find the lyrical density of the song to find how important the lyrics are to the song. Then we do some maths which to be honest I\'ve sort of forgotten what it was doing (because it was mainly trial and error to find a value I thought looked right. Impressive, I know). Now we can just average it with the audio valence, and we\'ve found our score!</p>\r\n<p>Of course I could sit here and contemplate typing a single sentence for several hours and generally being incredibly unsure of what I should be saying, but it would probably be better to just show the code as it would do a better job explaining  what it does than I would.</p>\r\n\r\n<pre>\r\n    audio           = spotify.get_audio_features(track[\'track\'][\'id\'])\r\n    audio_valence   = audio[\'valence\']\r\n    lyrical_valence = 0.9 if audio_valence > 0.3 else 0.9 - audio_valence\r\n    score           = round(audio_valence * 100)\r\n    incomplete      = \'yes\'\r\n\r\n    if \'error\' not in lyrics:\r\n        words = re.split(r\'[\\s\\]\\[]\', lyrics)\r\n        sad_words = 0\r\n        for word in words:\r\n            if word in Config.STOP_WORDS or word == \'\': words.remove(word)\r\n            if word in Config.LEXICON_SADNESS: sad_words += 5\r\n            if word in Config.LEXICON_FEAR: sad_words += 2.5\r\n            if word in Config.LEXICON_ANGER: sad_words += 1\r\n\r\n        percent_sad     = sad_words / len(words) * 100\r\n        lyrical_density = len(words) / track[\'track\'][\'duration_ms\'] * 1000\r\n        lyrical_valence = ((1 - (percent_sad * (1 + lyrical_density)) + 100) / 100)\r\n        incomplete      = \'no\'\r\n\r\n    score = round((audio_valence + lyrical_valence) / 2 * 100)\r\n</pre>\r\n\r\n<p>As you may have noticed, the <code>incomplete</code> flag was made because Genius doesn\'t always have the lyrics for a song so we have to guess how sad it\'s lyrics are (if it even has them). This is just based on the audio valence, because I like to assume sad instrumentals means sad song.</p>\r\n\r\n<p>That\'s the entire application, it\'s very small and I have a few more ideas that will probably never get implemented. But it did it\'s job in allowing me to learn some new stuff, and that\'s all that matters right?</p>','spds-thumb.png','spds,python,flask','no'),
	(5,'cross_site_tracing','Retro Exploits: Cross Site Tracing (XST)','2018-06-22','infosec','<p>In 2003, Microsoft attempted to protect against one of the most common forms of Cross Site Scripting by introducing the HttpOnly flag  in Internet Explorer 6, which prevented cookies from being accessed by JavaScript. A common attack was to access the document.cookie object and send it to a web server controlled by the attacker so that they can hijack the victim\'s session. Tagging a cookie as <code>httpOnly</code> forbids JavaScript to access it, protecting it from being sent to a third party. Cross Site Tracing (XST) was discovered by Jeremiah Grossman in 2003, and is a method used to bypass this protection by using the TRACE HTTP method. </p>\r\n\r\n<p>While this method is mostly deprecated now as modern browsers prevent TRACE methods from being made, I still think it\'s interesting to read about, and is simple enough to explain and allow me to practice blog writing. Now if you\'re thinking right now <i>\'But this was only 15 years ago, why are you calling it retro\'</i>? You are right, but you must consider that I was 3 years old when this was discovered, so it\'s pretty damn old for me.</p>\r\n\r\n<p>The TRACE method, according to  <a href=\"https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html\">RFC 2616</a>, \"allows the client to see what is being received at the other end of the request chain and use that data for testing or diagnostic information.\" Basically, it echos what is being sent to it for debugging purposes, allowing to see if the web server is malforming the request. The following is an example using cURL to form the header:</p>\r\n<pre>\r\n$ curl -X TRACE -H \"X-Header: test\" foo.com\r\nTRACE / HTTP/1.1\r\nUser-Agent: curl/7.24.0 \r\nHost: foo.com\r\nAccept: */*\r\nX-Header: test\r\n</pre>\r\n<p>As you can see it just sends the header back. Pretty harmless right? Well obviously not, because otherwise I wouldn\'t be writing about it. The problem is that TRACE will echo all the information you send to the server, this even includes cookies and Web Authentication strings as they are just headers as well.</p>\r\n\r\n<pre>\r\n&lt;script&gt;\r\n  var xmlhttp = new XMLHttpRequest();\r\n  var url = \'http://foo.com/\';\r\n\r\n  xmlhttp.withCredentials = true; // send cookie header\r\n  xmlhttp.open(\'TRACE\', url, false);\r\n  xmlhttp.send();\r\n\r\n  xmlDoc=xmlHttp.responseText;\r\n  alert(xmlDoc);\r\n&lt;/script&gt;\r\n</pre>\r\n\r\n<p>The above JavaScript code will send a TRACE request to the target web server. If the browser has a cookie from the target domain, the cookies will be shown on the alert. Of course this can be easily changed to do something more malicious such as sending the cookie to another server. XST successfully  grants  the  code  ability  bypass  <code>httpOnly</code>  while  accessing \r\ncookie data without the use of <code>document.cookie</code>. </p>\r\n\r\n<p>Although this would no longer work on modern browsers, I still think it is important to know that even something seemingly harmless such as the TRACE method can be used as an exploit. If you want to read more about it, you can go through the <a href =\"http://www.cgisecurity.com/whitehat-mirror/WH-WhitePaper_XST_ebook.pdf\">white paper</a> for XST written by Jeremiah Grossman.</p>','xst-thumb.png','xst,retro-exploits,xss','no'),
	(6,'aiohttp_deployment_guide','A Basic Deployment Guide For Aiohttp + Gunicorn + Nginx','2018-07-04','development','<p>In this guide we will be setting up a basic aiohttp app using Gunicorn and Nginx because the documentation on this I feel is very poor, as it took me a good few hours to figure out. Or maybe it was because I haven\'t used any of these technologies before... Either way, I didn\'t understand the documentation so I\'m writing my own.</p>\r\n<p>This guide assumes you are using Python3 and a Linux operating system with Systemd as the init system (e.g Ubuntu, CentOS, ...).</p>\r\n\r\n<h4>Table of Contents</h4>\r\n<ul>\r\n    <li><a href=\"#0x100\">Python Venv</a></li>\r\n    <li><a href=\"#0x200\">Aiohttp</a></li>\r\n    <li><a href=\"#0x300\">Systemd Unit</a></li>\r\n    <li><a href=\"#0x400\">Nginx Conf</a></li>\r\n</ul>\r\n\r\n<h3 id=\"0x100\">0x100: Python Venv</h3><hr>\r\n<p>The first thing everyone should always do everywhere no matter where they are, or who they with, or where they come from, or where they are going, is set up a virtual environment for Python. If you\'re app doesn\'t use a virtual environment, you\'re an idiot and you should create one <i><strong>RIGHT NOW.</strong></i> Here\'s how:</p>\r\n<p>Use the python module <code>venv</code> to create a virtual environment called <code>env</code> (or anything else you prefer).</p>\r\n<pre>[user@okcomputer]$ python -m venv env</pre>\r\n<p>And that\'s how you create a Python virtual environment. Now we want to install the <code>aiohttp</code> and <code>gunicorn</code> modules.</p>\r\n<p>Source the environment:</p>\r\n<pre>[user@okcomputer]$ source env/bin/activate</pre>\r\n<p>Install the modules:</p>\r\n<pre>(env) [user@okcomputer]$ pip install aiohttp gunicorn</pre>\r\n<p>That\'s all we need to get started for now. You can install any other libraries you want into the environment with pip.</p>\r\n\r\n<h3 id=\"0x200\">0x200: Aiohttp and Gunicorn</h3><hr>\r\n<p>With our new Python environment we are ready to create an aiohttp app! If you don\'t know, aiohttp is an asynchronous HTTP server/client. It\'s very useful when you\'re creating a web crawler that uses asyncio, but when you attempt to call it through a normal web framework, it doesn\'t work because as it turns out every good framework in existence is a blocking program so nothing works. So then you look for a framework that supports asycnio, then you find aiohttp and you\'re like <i>\'yeah this seems easy to use\'</i>. But <strong>NOPE</strong>, it turns out the documentation sucks, and the documentation that is there is for a completely different technology stack so you have no idea what to do because you only know Apache and neither aiohttp nor Gunicorn have documentation for it. So then your like <i>\'<strong>FUCK IT. </strong> I\'ll just buy another web sever, learn Nginx and put my crawler there\'.</i> So when you\'ve finished setting it up and it works all nice and good, you\'ve realised that it took way longer than it should have and so you write a blog post to rant about it because you don\'t like feeling as though it was wasted time.</p>\r\n\r\n<p>For this guide are writing a simple aiohttp application which we will call <code>myapp.py</code>.<p>\r\n<pre>\r\nfrom aiohttp import web\r\n\r\nasync def index(request):\r\n    return web.Response(text=\"I work!\")\r\n\r\nasync def factory():\r\n    app = web.Application()\r\n    app.router.add_get(\'/\', index)\r\n    return app\r\n</pre>\r\n\r\n<p>This is all we need to create a page that displays <code>I work!</code>. <code>factory</code> is our coroutine that returns the application instance for Gunicorn to use.</p>\r\n<p>Now we should test if Gunicorn is able to serve the project. We do this by name of the entry point (module) i.e. <code>myapp</code>, and the name of the app or application factory, i.e. <code>factory</code>, along with other Gunicorn settings provided as command line flags or in your config file. We will also use a custom worker subclass that aiohttp provides. The end result should look like this:</p>\r\n<pre>(env) [user@okcomputer]$ gunicorn myapp:factory --bind 0.0.0.0:8080 --worker-class aiohttp.GunicornWebWorker</pre>\r\n<p>Here we\'ve also bound it to <code>0.0.0.0:8080</code>, so now you can visit your sever\'s IP address in the browser appended with 8080 and you should see <code>I work!</code>.</p>\r\n<p>When you have confirmed that it works, you can close Gunicorn and deactivate the virtual environment.</p>\r\n\r\n<h3 id=\"0x300\">0x300: Systemd Unit</h3><hr>\r\n<p>The next thing to do is create a Systemd unit file so that when our server starts it automatically runs Gunicorn and serves our app. Create a unit file in <code>/etc/systemd/service/myapp.service</code>, where you can replace <code>myapp</code> with whatever your project is called.</p>\r\n<pre>\r\n[Unit]\r\nDescription=Gunicorn instance to serve myapp\r\nAfter=network.target\r\n\r\n[Service]\r\nUser=root\r\nGroup=www-data\r\nWorkingDirectory=/var/www/myappdirectory\r\nEnvironment=\"PATH=/var/www/myappdirectory/env/bin\"\r\nExecStart=/var/www/myappdirectory/env/bin/gunicorn myapp:factory --bind unix:myapp.sock --worker-class aiohttp.GunicornWebWorker \r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n</pre>\r\n\r\n<p>In the <code>[Service]</code> we map out the working directory and set the <code>PATH</code> environmental variable so that the init system knows where our the executables for the process are located (within our virtual environment). We\'ll then specify the commanded to start the service. Systemd requires that we give the full path to the Gunicorn executable, which is installed within our virtual environment.</p>\r\n\r\n<p>Now we can start and enable the service:</p>\r\n<pre>\r\n[user@okcomputer]$ sudo systemctl start myapp.service\r\n[user@okcomputer]$ sudo systemctl enable myapp.service\r\n</pre>\r\n\r\n<h3 id=\"0x400\">0x400: Nginx Conf</h3><hr>\r\n<p>If you\'ve noticed, in the Systemd unit, we\'ve bound Gunicorn to <code>unix:myapp.sock</code>. Now Gunicorn should be waiting for requests to the socket file <code>myapp.sock</code> in our project\'s directory. We need to configure Nginx to to pass requests into this socket. Here is an example of a server block you can use:</p>\r\n<pre>\r\nserver {\r\n    listen 80;\r\n    server_name myappdomain;\r\n\r\n    location / {\r\n        # checks for static file, if not found proxy to app\r\n        try_files $uri @proxy_to_app;\r\n    }\r\n\r\n    location @proxy_to_app {\r\n        include proxy_params;\r\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\r\n        proxy_set_header X-Forwarded-Proto $scheme;\r\n        proxy_set_header Host $http_host;\r\n        # we don\'t want nginx trying to do something clever with\r\n        # redirects, we set the Host: header above already.\r\n        proxy_redirect off;\r\n        proxy_pass http://unix:/var/www/myappdirectory/myapp.sock;\r\n    }\r\n}\r\n</pre>\r\n<p>That should be enough to get you started.</p>','aiohttp-deployment.png','aiohttp,gunicorn,nginx,python','no'),
	(7,'bad_malware_analysis','Let\'s Look At Malware I Got From Work','2018-07-06','infosec','<p>Today we\'re going to be looking a malware I received from a phishing attempt on my work email. Although I have zero skills in malware analysis, this piece of malware is very simple and uninteresting so this shouldn\'t take very long.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/wmal-email.png\" alt=\"image-alternative\">\r\n<p>Here\'s the email I received (with sensitive information censored). It\'s a wetransfer download link to a HTML file, so it\'s already incredibly suspicious because who would send a HTML file? Anyway, let\'s pop this bad boy into a virtual machine.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/wmal-html.png\" alt=\"image-alternative\">\r\n<sub>Fun fact: I forgot to create a snapshot before opening the file. Make sure to not do this.</sub>\r\n<p>As you can see, the file is just a fake Office 356 login page. Which confuses me even more because you can see from the address bar that you aren\'t logging into Office so why would you put your details in? It also looks more like a Google login page rather than Outlook which is more confusing! Although I have heard that at least two people from my office have tried to use it, so what would I know. Getting back on track, let\'s go and look at the source code, thankfully it is only HTML and I don\'t have to do any real reverse engineering as we can just look at the source code in plaintext.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/wmal-signin.png\" alt=\"image-alternative\">\r\n<p>While most of the code is in minified JavaScript and I\'m not bothered to go and un-minify it, we\'re just going to be looking at the stuff we can see immediately. The image above shows the HTML for the sign-in we saw earlier. <code>validateForm()</code> is just a function to validate the email address, nothing interesting there. But we can see that it sends a POST request to <code>kombiservis.co</code>, which would obviously be our attacker\'s domain.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/wmal-check.png\" alt=\"image-alternative\">\r\n<p>Going further down there\'s this interesting piece of code. I have no idea what it does, probably because it interacts with the minified code. Based on how it sets <code>iframeUri</code> to <code>https://accounts.youtube.com/accounts/CheckConnection</code>, I\'m going to go ahead and assume that it attempts to find if you\'re logged into YouTube and takes your credentials as the link is very similar to <code>https://accounts.youtube.com/accounts/SetSID</code> which is what Google uses to log you into YouTube when using other Google sites, such as Gmail.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/wmal-keylogger.png\" alt=\"image-alternative\">\r\n<p>The last piece we\'re going to look at is this simple keylogger, which puts the keys enter in the tab into the variable <code>keys</code> and sends it as a GET request parameter every 10 seconds to <code>wq14u.com</code>, which is a different domain to the one we saw earlier.</p>\r\n<p>I\'ve also heard from around the office that it sets up auto delete and reply rules on your email, which is probably something that\'s done when you enter your credentials into the form and POST them to the server.</p>\r\n<p>All in all, a very simple piece of malware which I may come back to at some point to un-minify the JavaScript and see if does anything more interesting.</p>\r\n','malware-look-thumb.png','malware,html','no'),
	(8,'honeypot_basics','An Introduction to Honeypots/Honeynets','2018-07-09','infosec','<blockquote><p>Prevention Is Ideal, But Detection Is A Must</p><footer>Eric Cole’s Four Basic Security Principles (No. 4)</footer></blockquote>\r\n<p>A honeypot or a collection of honeypots (honeynet) is a controlled vulnerable system created to lure attackers. A honeypot appears to be a legitimate part of the site, but is actually isolated and monitored, and that seems to contain information or a resource of value to attackers. This allows honeypots to act a an early warning system, deceiving attackers, perhaps delaying and identifying them, and then ultimately supporting efforts to shut down the attack.</p>\r\n\r\n<p>In general, you would use a honeypot to understand what is happening in key systems. If a web server is receiving thousands or millions of hits per day, it can be hard to differentiate between legitimate connections and attackers. Honeypots allow you to have a way to analyse attack traffic as your honeypot should have no legitimate users, allowing you to quickly identify attack traffic and create counter-measures.</p>\r\n\r\n<p>There are 3 types of honeypots; low, medium and high interaction. Each type provides varying levels of security/detection difficulty, intelligence, and setup complexity. High interaction honeypots imitate the activities of the production systems that host a variety of services and, therefore, an attacker may be allowed a lot of services to waste their time. However, they use a lot of resources and can be complicated to setup. On the other hand, low interactions honeypots are easy to setup but provide the least amount of intelligence, as they only simulate the services frequently visited by attackers.</p>\r\n\r\n<p>As an example, we will be looking at <a href=\"https://www.anomali.com/platform/modern-honey-net\">Modern Honey Network (MHN)</a>, a honeypot management service by Anomali, which allows you to quickly deploy and manage honeypots. It utilises the HPfeeds protocol to centralise the data into a MongoDB instance for analysis.</p>\r\n\r\n<p>MHN consists of a management server and one or more honeypots. The management server is where the honeypots send their data to, and creates a Flask app to make the data easily viewable from a web interface. A big advantage of MHN is it\'s simplicity and variety of honeypot deployment options. Honeypot deploy scripts include several common honeypot technologies, including: </p>\r\n<ul>\r\n<li><strong>Snort:</strong>  An open source intrusion prevention system capable of real-time traffic analysis and packet logging. It is not a honeypot per se, but an IDS/IPS, and is  very helpful to detect attacks on your network. Sourcefire (the creator of Snort) was a acquired by Cisco but the product Snort remains open source.</li>\r\n<li><strong>Suricata:</strong> An IDS/IPS much like Snort.</li>\r\n<li><strong>Dionaea:</strong> A low interaction honeypot which exposes services like SMB, MSSQL, SIP, HTTP, FTP, TFTP. It is mainly used to trap malware exploiting vulnerabilities exposed by services offered to a network, and attempts to get a copy of it.</li>\r\n<li><strong>Glastopf:</strong> A very popular Python web application honeypot that has the ability to emulate thousands of web vulnerabilities. It is no longer actively developed but it is \"maintained\" according to the developers. </li>\r\n<li><strong>Cowrie:</strong> A medium interaction SSH and Telnet honeypot designed to log brute force attacks and the shell interaction performed by the attacker.  It has SFTP support, SCP support, direct-tcpip (proxying) support and many other features.</li>\r\n<li><strong>p0f:</strong> A tool that that uses passive fingerprinting to identify the OS behind a TCP connection.</li>\r\n<li><strong>Conpot:</strong> A low interaction Industrial Control Systems honeypot and basically emulates some protocols used in industrial environments.</li>\r\n<li><strong>Wordpot:</strong> A WordPress emulator honeypot which detects probes for plugins, themes, timthumb and other common files used to fingerprint a Wordpress installation.</li>\r\n<li><strong>ShockPot:</strong> A web app honeypot designed to find attackers attempting to exploit the Bash remote vulnerability CVE-2014-6271.</li>\r\n</ul>\r\n<p>From these, it should be easy to see the application of honeypots and their usefulness. However, as with any technology, there is no perfect solution. If compromised, a honeypot or honeynet can act as a springboard to launch additional system attacks to the \"real\" servers. In some cases, honeypots can decrease and organization\'s security by being more attractive to attacks and that the establishment of a vulnerable system can constitute as \"gross negligence\". In order for your honeypot to be effective, it must be monitored continually.</p>\r\n','honeypot-thumb.png','honeypot,honeynet','no'),
	(9,'rainbow_tables','I Learn To Draw Diagrams and You Learn About Rainbow Tables','2018-07-17','infosec','<p>As most people should know, a Rainbow Table is a way of mapping a plaintext to it\'s hash by storing the plaintext -> hash combo in a file on the hard drive. However, storing every hash individually takes up an amount of space nobody could ever have. There is much more going under the hood of a Rainbow Table, and today we are going to look at how it attempts to minimise the memory it takes up.</p>\r\n\r\n<p>Generating a Rainbow Table uses two key functions: a hash function and a reduction function. The hash function maps a plaintext to a hash.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/hash.png\" alt=\"image-alternative\" style=\"margin: auto;\">\r\n\r\n<p>While the reduction function maps a hash to a plaintext. The reduction function obviously does not generate the original plaintext of the hash, it is not an <i>inverse</i> hashing function because that should be impossible. What the reduction function does is create a new plaintext from the hash. The reduction function is a key part of the Rainbow Table and is very complicated. So for the purposes of this article, we will keep it simple. In our case we will have a reduction function that takes the first 7 characters of a hash.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/reduction.png\" alt=\"image-alternative\" style=\"margin: auto;\">\r\n\r\n<p>A rainbow table is made of up of chains of hashes and reductions. A chain starts with an arbitrary plaintext and ends with a hash. The plaintext will go through the process of being hashed and reduced millions of times. The table only stores the starting plaintext, and the final hash you choose to end with, and so a chain \"containing\" millions of hashes can be represented with only a single starting plaintext, and a single finishing hash.</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/chain.png\" alt=\"image-alternative\" style=\"margin: auto;\">\r\n\r\n<p>Now that we have our table of chains. We can start looking for an unknown plaintext with a hash. Here is the process:</p>\r\n<img class=\"img-responsive\" src=\"/common/static/img/rainbow-process.png\" alt=\"image-alternative\" style=\"margin: auto;\">\r\n\r\n<p>In this way you check through the hashes in the chains, which aren\'t actually stored anywhere on disk, by iterating column by column through the table of chains, backwards from the last column in the chain, to the starting plaintext.</p>\r\n\r\n<p>The reason they\'re called Rainbow Tables is because each column uses a different reduction function. If each reduction function was a different color, and you have starting plaintexts at the top and final hashes at the bottom, it would look like a rainbow (a very vertically long and thin one).</p>\r\n','rainbow-thumb.png','rainbow','no'),
	(10,'macbook_impressions','MacBook & MacOS First Impressions','2018-07-25','miscellaneous','<p>A week ago I bought a new 2018 13\" MacBook Pro. As my first dive into the Apple ecosystem, I\'d say it went quite well (even if the thumbnail says otherwise). Here are my initial thoughts on it.</p>\r\n<h3>Hardware</h3>\r\n<p>These are some of the things I care about when looking at computer hardware in no particular order.</p>\r\n<ul>\r\n	<li><strong>Keyboard:</strong> I actually like it more than normal membrane keyboards, especially laptop keyboards, mainly due to the short travel time. I would be using a mechanical keyboard instead so this wouldn\'t be an issue, except the next point makes it a lot harder.</li>\r\n	<li><strong>Output Ports:</strong> There are only 4 USB-C ports. That\'s it. It\'s cool that there is a headphone jack (that shouldn\'t deserve praise, but here we are), but 4 ports is not nearly enough for anyone, <i>ESPECIALLY</i> when the charger takes up one of them. I don\'t have any peripherals that even use USB-C, so I would have to buy dongles for all 4 ports, which is very stupid and a waste of money.</li>\r\n	<li><strong>The Touchbar.</strong> I kinda like it. I\'ve been using it a lot more than I expected to. Going between a tactile keyboard to a touchscreen can be jarring, and I always have to look at what I\'m trying to press, but I don\'t hate it. Except for the fact that it replaces the ESC key. <i>THIS</i> is the probably the thing I hate the most about the touchbar, even if it sounds stupid. The problem is that I use Vim for everything, which means I press ESC very often. I don\'t know where the ESC key is on the touchbar (because it\'s not tactile), so I always miss it. So now I\'ve had to map caps lock to ESC (which was very easy to do actually), but this messes up my muscle memory as caps lock would normally be mapped to backspace for me.</li>\r\n	<li><strong>The CPU & RAM:</strong> I got the base model MacBook (i5 + 8gb) which is actually fine for me. So far I haven\'t come across any issues with it being too slow, nothing I do is very hardware intensive as most of the code I write is more I/O intensive than computation intensive. It gets the job done, although $2500 AUD for and i5 and 8gb of RAM is quite expensive.</li>\r\n	<li><strong>The Chasis:</strong> It looks nice. Actually, it looks VERY nice. I have no complaints, it feels like a premium product. Although, I haven\'t had much experience with other modern laptops, I\'d say it\'s the best looking, and best feeling laptop on the market.</li>  \r\n</ul>\r\n\r\n<p>So far these impressions are pretty mixed. It certainly doesn\'t look like it\'s worth $2500, but that\'s all changed with the software (sort of).</p>\r\n\r\n<h3>Software</h3>\r\n<p>I\'ve used switched between Windows and Linux as my daily OS for most of my life, although Linux has been sticking around for much longer during the past few years. I\'ve never touched MacOS for any more than five minutes before. So we are just going to look at whether we can do the same things on MacOS as we can on Windows and Linux.</p>\r\n\r\n<h4>Windows</h4>\r\n<p><strong>Can it play video games?</strong><br>No. Not the ones I want to play.<p>\r\n<p>Turns out that video games is all I use Windows for. Guess I\'m still going to have to keep a separate computer for it then.</p>\r\n\r\n<h4>Linux</h4>\r\n<p><strong>Can you rice it?</strong><br>Yes, I think. Haven\'t looked into it because it already looks pretty good.</p>\r\n<p><strong>Is the terminal powerful enough for me to be able to ignore everything else?</strong><br>No. Even though I use zsh just like on Linux, MacOS doesn\'t let you do everything. It is good enough to do most of what I want however (it\'s light years ahead of Windows).</p>\r\n<p><strong>Does it have a good package manager</strong><br>Not really. Homebrew is helpful, but is in no way a replacement for something like Pacman, let alone the AUR.</p>\r\n<p><strong>Does software constantly break because nobody supports Linux?</strong><br>No. MacOS also has Sequel Pro, which is probably the best MySQL viewer in existence.</p>\r\n<p><strong>Does Xorg break every time you update the computer?</strong><br>No.</p>\r\n<p><strong>Do you constantly have to go into conf files to fix things?</strong><br>No.</p>\r\n\r\n<p>Ok, it looks like this starting to become a rant on Arch Linux so I\'m just going to stop here. The point is that MacOS, with all it\'s shitty proprietary software restrictions, is incredibly easy to use. Even though most of my issues with Linux are mainly from using a distro like Arch, it\'s been a whole week I haven\'t had any problems with it. I haven\'t had to mess with any drivers or config files, everything just worked out of the box.</p>\r\n\r\n<p>A few years ago I probably would have hated this, because I preferred constantly breaking my computer and learning how to fix it. But now I have a job and actual things to do. I don\'t have time to spend a whole weekend reading man pages. Although I would say I have learnt enough where I could fix a problem that would have taken me a day to now only take a few minutes, I can\'t be bothered with it anymore.</p>\r\n\r\n<p>Right now I have three computers running on three operating systems. Windows at home for video games, Linux at work (even though I probably shouldn\'t), and now MacOS for personal use. Based on this short experience I can pretty safely say that Windows is the worst operating system ever created, and is holding video games as hostage. Hopefully I\'ll be able to ditch Windows very soon and never have to come back to that dumpster fire ever again.</p>','macbook-thumb.png','macos,macbook','no');

/*!40000 ALTER TABLE `Articles` ENABLE KEYS */;
UNLOCK TABLES;



/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;
/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
